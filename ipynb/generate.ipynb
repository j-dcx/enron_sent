{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ngRpcpzhUtn5"},"outputs":[],"source":["#https://github.com/rybread1/trump-speech-writer2"]},{"cell_type":"markdown","metadata":{"id":"Ry4e14sQD8W3"},"source":["###Initialize variables"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19439,"status":"ok","timestamp":1665345134476,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"crLumu2HbNcU","outputId":"ca247d09-2797-45bf-c348-4062a27a1025"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.9 MB 5.2 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.6 MB 45.9 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 163 kB 42.7 MB/s \n","\u001b[?25h"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import datetime\n","import itertools\n","from collections import Counter\n","import re\n","import os\n","import pandas as pd\n","\n","!pip install transformers -q"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23514,"status":"ok","timestamp":1665345159555,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"fz95fB-FbnlL","outputId":"c1ff7c89-a3d9-4f55-ea3a-801c99b83009"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":148,"metadata":{"executionInfo":{"elapsed":300,"status":"ok","timestamp":1665358134685,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"nEsXjyOBzVza"},"outputs":[],"source":["lang = 'no'"]},{"cell_type":"code","execution_count":149,"metadata":{"executionInfo":{"elapsed":9034,"status":"ok","timestamp":1665358144130,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"YALCdYcScctQ"},"outputs":[],"source":["df_orig = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/final/' + lang + '/data/data_users_as_labels-sent_clean_' + lang + '.csv')"]},{"cell_type":"code","execution_count":150,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1665358144134,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"p4RBqPMYABbK","outputId":"e3601419-ad06-47be-e692-471385df7af0"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cclass 'pandas.core.frame.DataFrame'\u003e\n","RangeIndex: 39624 entries, 0 to 39623\n","Data columns (total 8 columns):\n"," #   Column             Non-Null Count  Dtype \n","---  ------             --------------  ----- \n"," 0   Unnamed: 0         39624 non-null  int64 \n"," 1   text               39624 non-null  object\n"," 2   user               39624 non-null  object\n"," 3   folder             39624 non-null  object\n"," 4   lang               39624 non-null  object\n"," 5   length             39624 non-null  int64 \n"," 6   translation        39624 non-null  object\n"," 7   translation_clean  39617 non-null  object\n","dtypes: int64(2), object(6)\n","memory usage: 2.4+ MB\n"]}],"source":["df_orig.info()"]},{"cell_type":"code","execution_count":151,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1665358144135,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"f9rUQX2_BXxG","outputId":"928a1859-6084-4065-96b9-b60f89b0e662"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-a61edc5f-3ce7-4798-bf8a-d69190352f49\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eUnnamed: 0\u003c/th\u003e\n","      \u003cth\u003etext\u003c/th\u003e\n","      \u003cth\u003euser\u003c/th\u003e\n","      \u003cth\u003efolder\u003c/th\u003e\n","      \u003cth\u003elang\u003c/th\u003e\n","      \u003cth\u003elength\u003c/th\u003e\n","      \u003cth\u003etranslation\u003c/th\u003e\n","      \u003cth\u003etranslation_clean\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e\\n I don't know if you got these.\\n ----------...\u003c/td\u003e\n","      \u003ctd\u003ebass-e\u003c/td\u003e\n","      \u003ctd\u003esent\u003c/td\u003e\n","      \u003ctd\u003eno\u003c/td\u003e\n","      \u003ctd\u003e545\u003c/td\u003e\n","      \u003ctd\u003eJeg vet ikke om du har disse.\\n --------------...\u003c/td\u003e\n","      \u003ctd\u003evite $. ---------------------- videresendt eri...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e\\n Can you spell S-N-O-O-T-Y?\\n \\n e\\n \\n \\n  ...\u003c/td\u003e\n","      \u003ctd\u003ebass-e\u003c/td\u003e\n","      \u003ctd\u003esent\u003c/td\u003e\n","      \u003ctd\u003eno\u003c/td\u003e\n","      \u003ctd\u003e460\u003c/td\u003e\n","      \u003ctd\u003eKan du stave S-N-O-O-T-Y?\\n \\n e\\n \\n \\n    \\n...\u003c/td\u003e\n","      \u003ctd\u003estave s-n-o-o-t-y $? e $: ami chokshi enron 01...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e\\n The new deal #s are 147888,147889.\\n \\n -E\u003c/td\u003e\n","      \u003ctd\u003ebass-e\u003c/td\u003e\n","      \u003ctd\u003esent\u003c/td\u003e\n","      \u003ctd\u003eno\u003c/td\u003e\n","      \u003ctd\u003e42\u003c/td\u003e\n","      \u003ctd\u003eDe nye avtalenummerene er 147888,147889.\\n \\n -E\u003c/td\u003e\n","      \u003ctd\u003eny avtalenummer 147888,147889. -e\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e\\n I think I sent this to the worng e-mail add...\u003c/td\u003e\n","      \u003ctd\u003ebass-e\u003c/td\u003e\n","      \u003ctd\u003esent\u003c/td\u003e\n","      \u003ctd\u003eno\u003c/td\u003e\n","      \u003ctd\u003e167\u003c/td\u003e\n","      \u003ctd\u003eJeg tror jeg sendte dette til den slitte e-pos...\u003c/td\u003e\n","      \u003ctd\u003etro sende slite e-postadresse f√∏rste gang $( s...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e\\n We are going to Woody's tonight if you are ...\u003c/td\u003e\n","      \u003ctd\u003ebass-e\u003c/td\u003e\n","      \u003ctd\u003esent\u003c/td\u003e\n","      \u003ctd\u003eno\u003c/td\u003e\n","      \u003ctd\u003e64\u003c/td\u003e\n","      \u003ctd\u003eVi skal til Woody's i kveld hvis du er interes...\u003c/td\u003e\n","      \u003ctd\u003ewoody's kveld interessere $. $-e\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a61edc5f-3ce7-4798-bf8a-d69190352f49')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-a61edc5f-3ce7-4798-bf8a-d69190352f49 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a61edc5f-3ce7-4798-bf8a-d69190352f49');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["   Unnamed: 0                                               text    user  \\\n","0           0  \\n I don't know if you got these.\\n ----------...  bass-e   \n","1           1  \\n Can you spell S-N-O-O-T-Y?\\n \\n e\\n \\n \\n  ...  bass-e   \n","2           2      \\n The new deal #s are 147888,147889.\\n \\n -E  bass-e   \n","3           3  \\n I think I sent this to the worng e-mail add...  bass-e   \n","4           4  \\n We are going to Woody's tonight if you are ...  bass-e   \n","\n","  folder lang  length                                        translation  \\\n","0   sent   no     545  Jeg vet ikke om du har disse.\\n --------------...   \n","1   sent   no     460  Kan du stave S-N-O-O-T-Y?\\n \\n e\\n \\n \\n    \\n...   \n","2   sent   no      42   De nye avtalenummerene er 147888,147889.\\n \\n -E   \n","3   sent   no     167  Jeg tror jeg sendte dette til den slitte e-pos...   \n","4   sent   no      64  Vi skal til Woody's i kveld hvis du er interes...   \n","\n","                                   translation_clean  \n","0  vite $. ---------------------- videresendt eri...  \n","1  stave s-n-o-o-t-y $? e $: ami chokshi enron 01...  \n","2                  ny avtalenummer 147888,147889. -e  \n","3  tro sende slite e-postadresse f√∏rste gang $( s...  \n","4                   woody's kveld interessere $. $-e  "]},"execution_count":151,"metadata":{},"output_type":"execute_result"}],"source":["df_orig.head()"]},{"cell_type":"code","execution_count":152,"metadata":{"executionInfo":{"elapsed":34,"status":"ok","timestamp":1665358144135,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"tpNbQFKVc3-o"},"outputs":[],"source":["df = df_orig[['translation']].sample(100)"]},{"cell_type":"code","execution_count":153,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1665358144136,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"Gv98kdEzZFGO","outputId":"6f4a390d-5ec1-41ba-a66a-8a22dbf9ca1e"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cclass 'pandas.core.frame.DataFrame'\u003e\n","Int64Index: 100 entries, 816 to 8247\n","Data columns (total 1 columns):\n"," #   Column       Non-Null Count  Dtype \n","---  ------       --------------  ----- \n"," 0   translation  100 non-null    object\n","dtypes: object(1)\n","memory usage: 1.6+ KB\n"]}],"source":["df.info()"]},{"cell_type":"markdown","metadata":{"id":"e2pZvuHuD0iS"},"source":["###Initialize custom tokenizer"]},{"cell_type":"code","execution_count":154,"metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1665358144137,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"IvtnK-My_og5"},"outputs":[],"source":["train_path = '/content/drive/MyDrive/Colab Notebooks/final/' + lang + '/generate/train_dataset_' + lang + '.txt'\n","test_path = '/content/drive/MyDrive/Colab Notebooks/final/' + lang + '/generate/test_dataset_' + lang + '.txt'"]},{"cell_type":"code","execution_count":155,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1665358144138,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"nhQTAJRE96aT","outputId":"e76e68f9-a0e1-4e4f-cb18-eeb0864844d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train dataset length: 85\n","Test dataset length: 15\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","def build_text_files(txts, dest_path):\n","    f = open(dest_path, 'w')\n","    data = ''\n","    for txt in txts:\n","        summary = txt.strip()\n","        summary = re.sub(r\"\\s\", \" \", summary)\n","        data += summary + \"  \"\n","    f.write(data)\n","\n","train, test = train_test_split(df.translation, test_size=0.15)\n","\n","build_text_files(train, train_path)\n","build_text_files(test, test_path)\n","\n","print(\"Train dataset length: \"+str(len(train)))\n","print(\"Test dataset length: \"+ str(len(test)))"]},{"cell_type":"code","execution_count":156,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1665358144138,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"k8hwpKGw-45l","outputId":"69184636-9854-4ae7-f156-865e1daab672"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading file vocab.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/909a290700bd99135e67c64eefc166960b67cfd2/vocab.json\n","loading file merges.txt from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/909a290700bd99135e67c64eefc166960b67cfd2/merges.txt\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/909a290700bd99135e67c64eefc166960b67cfd2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.22.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n"]}],"source":["from transformers import GPT2Tokenizer\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"]},{"cell_type":"markdown","metadata":{"id":"B4h07XuJgG8P"},"source":["###Train custom tokenizer"]},{"cell_type":"code","execution_count":157,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1665358144139,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"qPNMn2xn_GfF"},"outputs":[],"source":["dataset = df.translation.tolist()"]},{"cell_type":"code","execution_count":158,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1665358144139,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"A7MDkguqabFI","outputId":"dfbfc2b6-1946-416a-b1d0-43d2fd30fea9"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Ingen stor sak. Jeg pr√∏ver bare √• binde opp l√∏se tr√•der n√•r jeg kan. Jeg mistenker\\n de m√• ha f√•tt betalt, ellers ville noen klaget.'"]},"execution_count":158,"metadata":{},"output_type":"execute_result"}],"source":["dataset[3]"]},{"cell_type":"code","execution_count":159,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1665358144140,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"54Jah3nTae6Y"},"outputs":[],"source":["batch_size = 1000\n","def batch_iterator():\n","    for i in range(0, len(dataset), batch_size):\n","        yield dataset[i : i + batch_size]"]},{"cell_type":"code","execution_count":160,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1665358144140,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"790uteElapAA","outputId":"c5945ce6-0ec3-4629-933b-d69522c12ad6"},"outputs":[{"name":"stderr","output_type":"stream","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/909a290700bd99135e67c64eefc166960b67cfd2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.22.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading file vocab.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/909a290700bd99135e67c64eefc166960b67cfd2/vocab.json\n","loading file merges.txt from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/909a290700bd99135e67c64eefc166960b67cfd2/merges.txt\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/909a290700bd99135e67c64eefc166960b67cfd2/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/909a290700bd99135e67c64eefc166960b67cfd2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.22.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n"]}],"source":["from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"]},{"cell_type":"code","execution_count":161,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1665358144141,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"VDv4iTA_3rvw"},"outputs":[],"source":["tokenizer_name = 'gpt2-tokenizer_' + lang"]},{"cell_type":"code","execution_count":162,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1032,"status":"ok","timestamp":1665358145156,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"pDHU89M0aq1l","outputId":"bdc260b6-f9c4-4e1a-8ce5-ae974fe74c3a"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 738 ms, sys: 161 ms, total: 899 ms\n","Wall time: 863 ms\n"]}],"source":["%%time\n","new_tokenizer = tokenizer.train_new_from_iterator(batch_iterator(), vocab_size=25000)"]},{"cell_type":"code","execution_count":163,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1665358145156,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"r_yTplB7ayS4","outputId":"8dc120a3-9ee2-4c0c-cbab-0590627e7e89"},"outputs":[{"name":"stderr","output_type":"stream","text":["tokenizer config file saved in /content/drive/MyDrive/Colab Notebooks/final/no/generate/gpt2-tokenizer_no/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/Colab Notebooks/final/no/generate/gpt2-tokenizer_no/special_tokens_map.json\n"]},{"data":{"text/plain":["('/content/drive/MyDrive/Colab Notebooks/final/no/generate/gpt2-tokenizer_no/tokenizer_config.json',\n"," '/content/drive/MyDrive/Colab Notebooks/final/no/generate/gpt2-tokenizer_no/special_tokens_map.json',\n"," '/content/drive/MyDrive/Colab Notebooks/final/no/generate/gpt2-tokenizer_no/vocab.json',\n"," '/content/drive/MyDrive/Colab Notebooks/final/no/generate/gpt2-tokenizer_no/merges.txt',\n"," '/content/drive/MyDrive/Colab Notebooks/final/no/generate/gpt2-tokenizer_no/added_tokens.json',\n"," '/content/drive/MyDrive/Colab Notebooks/final/no/generate/gpt2-tokenizer_no/tokenizer.json')"]},"execution_count":163,"metadata":{},"output_type":"execute_result"}],"source":["new_tokenizer.save_pretrained('/content/drive/MyDrive/Colab Notebooks/final/' + lang + '/generate/'+tokenizer_name)"]},{"cell_type":"code","execution_count":164,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1665358145157,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"h4OynMSIbKYD","outputId":"30fed9a6-666f-4f0e-f004-8b9a2f168f0c"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading file vocab.json\n","loading file merges.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/Colab Notebooks/final/' + lang + '/generate/' + tokenizer_name)"]},{"cell_type":"markdown","metadata":{"id":"cyqWPaIlgNHn"},"source":["###Train model"]},{"cell_type":"code","execution_count":165,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":378,"status":"ok","timestamp":1665358145529,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"Wf8TFMh20C30","outputId":"340809c2-adb9-49a8-9690-b9ac564c43c4"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  FutureWarning,\n","Creating features from dataset file at /content/drive/MyDrive/Colab Notebooks/final/no/generate\n","Token indices sequence length is longer than the specified maximum sequence length for this model (37901 \u003e 1024). Running this sequence through the model will result in indexing errors\n","Saving features into cached file /content/drive/MyDrive/Colab Notebooks/final/no/generate/cached_lm_GPT2TokenizerFast_16_train_dataset_no.txt [took 0.008 s]\n","Creating features from dataset file at /content/drive/MyDrive/Colab Notebooks/final/no/generate\n","Saving features into cached file /content/drive/MyDrive/Colab Notebooks/final/no/generate/cached_lm_GPT2TokenizerFast_16_test_dataset_no.txt [took 0.005 s]\n"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 344 ms, sys: 12.8 ms, total: 357 ms\n","Wall time: 471 ms\n"]}],"source":["%%time\n","from transformers import TextDataset,DataCollatorForLanguageModeling\n","\n","def load_dataset(train_path,test_path,tokenizer):\n","\n","    train_dataset = TextDataset(\n","          tokenizer=tokenizer,\n","          file_path=train_path,\n","          block_size=16)\n","\n","    test_dataset = TextDataset(\n","          tokenizer=tokenizer,\n","          file_path=test_path,\n","          block_size=16)\n","\n","    data_collator = DataCollatorForLanguageModeling(\n","        tokenizer=tokenizer, mlm=False,\n","\n","    )\n","    return train_dataset,test_dataset,data_collator\n","\n","train_dataset, test_dataset, data_collator = load_dataset(train_path, test_path, tokenizer)"]},{"cell_type":"code","execution_count":166,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1665358145530,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"4YHMiFkFCDtf","outputId":"e247d960-326a-4e07-b61c-e117600ec711"},"outputs":[{"data":{"text/plain":["2368"]},"execution_count":166,"metadata":{},"output_type":"execute_result"}],"source":["len(train_dataset.examples)"]},{"cell_type":"code","execution_count":167,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7758,"status":"ok","timestamp":1665358153283,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"KgVRGHb34Mv5","outputId":"86ad5fe1-1abf-493b-f579-e50dc72e04ff"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/909a290700bd99135e67c64eefc166960b67cfd2/config.json\n","Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.22.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/909a290700bd99135e67c64eefc166960b67cfd2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"]}],"source":["from transformers import Trainer, TrainingArguments, GPT2LMHeadModel\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"]},{"cell_type":"code","execution_count":168,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1665358153284,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"-VoyT3G60IYi","outputId":"642d1994-e417-417e-ac52-30ddd644a586"},"outputs":[{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 13.2 ms, sys: 3.01 ms, total: 16.2 ms\n","Wall time: 37.8 ms\n"]}],"source":["%%time\n","training_args = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/Colab Notebooks/final/' + lang + '/generate/gpt2_' + lang, #The output directory\n","    overwrite_output_dir=True, #overwrite the content of the output directory\n","    num_train_epochs=3, # number of training epochs\n","    per_device_train_batch_size=32, # batch size for training\n","    per_device_eval_batch_size=64,  # batch size for evaluation\n","    eval_steps = 400, # Number of update steps between two evaluations.\n","    save_steps=800, # after # steps model is saved\n","    warmup_steps=500,# number of warmup steps for learning rate scheduler\n","    )\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset\n",")\n","    #prediction_loss_only=True,"]},{"cell_type":"markdown","metadata":{"id":"TFRv14YYFKgq"},"source":["###Train model fo real"]},{"cell_type":"code","execution_count":169,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":483},"executionInfo":{"elapsed":614196,"status":"ok","timestamp":1665359942523,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"xDWvatt80YbJ"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 2368\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed \u0026 accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 222\n"]},{"data":{"text/html":["\n","    \u003cdiv\u003e\n","      \n","      \u003cprogress value='222' max='222' style='width:300px; height:20px; vertical-align: middle;'\u003e\u003c/progress\u003e\n","      [222/222 29:36, Epoch 3/3]\n","    \u003c/div\u003e\n","    \u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n"," \u003ctr style=\"text-align: left;\"\u003e\n","      \u003cth\u003eStep\u003c/th\u003e\n","      \u003cth\u003eTraining Loss\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\u003cp\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 29min 11s, sys: 37.8 s, total: 29min 49s\n","Wall time: 29min 48s\n"]},{"data":{"text/plain":["TrainOutput(global_step=222, training_loss=8.568015708579674, metrics={'train_runtime': 1788.7371, 'train_samples_per_second': 3.972, 'train_steps_per_second': 0.124, 'total_flos': 58006831104000.0, 'train_loss': 8.568015708579674, 'epoch': 3.0})"]},"execution_count":169,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","trainer.train()"]},{"cell_type":"code","execution_count":170,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3516,"status":"ok","timestamp":1665359946033,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"7Sppyt3T0kVG","outputId":"badbe417-e87e-4da2-f547-0100af5e4498"},"outputs":[{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/final/no/generate/\n","Configuration saved in /content/drive/MyDrive/Colab Notebooks/final/no/generate/config.json\n","Model weights saved in /content/drive/MyDrive/Colab Notebooks/final/no/generate/pytorch_model.bin\n"]}],"source":["trainer.save_model('/content/drive/MyDrive/Colab Notebooks/final/' + lang + '/generate/')"]},{"cell_type":"code","execution_count":171,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2501,"status":"ok","timestamp":1665359948523,"user":{"displayName":"JƒÅnis Ducens","userId":"07163689454887064407"},"user_tz":-180},"id":"dDYPNR6rVaMW","outputId":"67f7b846-770c-4f5f-b177-511a3cbe4b5d"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file /content/drive/MyDrive/Colab Notebooks/final/no/generate/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.22.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file /content/drive/MyDrive/Colab Notebooks/final/no/generate/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/final/no/generate/.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"]}],"source":["model_generate = GPT2LMHeadModel.from_pretrained('/content/drive/MyDrive/Colab Notebooks/final/' + lang + '/generate/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D5bd8pO101HB","outputId":"17699686-a386-4e3a-8d5d-980528ddc733"},"outputs":[{"name":"stderr","output_type":"stream","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/909a290700bd99135e67c64eefc166960b67cfd2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.22.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading file vocab.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/909a290700bd99135e67c64eefc166960b67cfd2/vocab.json\n","loading file merges.txt from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/909a290700bd99135e67c64eefc166960b67cfd2/merges.txt\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/909a290700bd99135e67c64eefc166960b67cfd2/tokenizer.json\n"]}],"source":["from transformers import pipeline\n","\n","generate = pipeline('text-generation', model=model_generate, tokenizer='gpt2', config={'max_length':10000, 'temperature': .5})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YO5q-nwqWKux"},"outputs":[],"source":["initial_seed = df.sample(1).values[0][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1OQh-vHlbJim"},"outputs":[],"source":["initial_seed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2pP1IqJn3kVv"},"outputs":[],"source":["%%time\n","text = generate(initial_seed, max_length=250, min_length=100, do_sample=True, temperature=1.2)[0]['generated_text']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZwXsLjtP4iZo"},"outputs":[],"source":["text"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"","provenance":[{"file_id":"1mFkyxkXvgEZ1kyULaNl8AcjGbeS8O3-N","timestamp":1664398786820}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}